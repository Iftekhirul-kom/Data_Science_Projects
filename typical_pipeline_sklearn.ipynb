{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Iftekhirul-kom/Data_Science_Projects/blob/main/typical_pipeline_sklearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgaktm_p_Jrf"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2HuPBnsZJho"
      },
      "source": [
        "# The dataset crx.csv is available [here](https://drive.google.com/file/d/1St5_fkwdySSlNgeLthqeaOh1jATxnCj2/view?usp=sharing)\n",
        "# The dataset post-operative.csv is available [here](https://drive.google.com/file/d/1yR8mLtACWjefoKam1XaCY1jVgA5tP0wT/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrfcCegt8ffq"
      },
      "source": [
        "import pandas as pd\n",
        "from pandas.api.types import is_string_dtype\n",
        "\n",
        "data = pd.read_csv('crx.csv', na_values='?')\n",
        "\n",
        "data1 = pd.read_csv('post-operative.csv', na_values='?')\n",
        "\n",
        "for col in data1.columns:\n",
        "  if is_string_dtype(data1[col].dtype):\n",
        "    data1[col] = data1[col].str.strip()\n",
        "\n",
        "for col in data.columns:\n",
        "  if is_string_dtype(data[col].dtype):\n",
        "    data[col] = data[col].str.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z0aIiTr_OPt"
      },
      "source": [
        "# Split Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ToFDUk2_QBo"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = data.loc[:, data.columns != 'Class']\n",
        "y = data['Class']\n",
        "\n",
        "x1 = data1.loc[:, data1.columns != 'Label']\n",
        "y1 = data1['Label']\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.1, stratify=y, random_state=1)\n",
        "train_x1, test_x1, train_y1, test_y1 = train_test_split(x1, y1, test_size=0.1, stratify=y1, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQpbf58wCVuf"
      },
      "source": [
        "# Handle Missing Values (DROP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUrgOmUECbgg",
        "outputId": "f8e71149-11a0-4a9c-9ed5-b10a480f0eb4"
      },
      "source": [
        "train = pd.concat([train_x, train_y], axis=1)\n",
        "test = pd.concat([test_x, test_y], axis=1)\n",
        "\n",
        "train = train.dropna()\n",
        "test = test.dropna()\n",
        "\n",
        "print(train.isnull().values.any())\n",
        "\n",
        "drop_train_x = train.loc[:, data.columns != 'Class']\n",
        "drop_train_y = train['Class']\n",
        "drop_test_x = test.loc[:, data.columns != 'Class']\n",
        "drop_test_y = test['Class']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNn554NBFVu7"
      },
      "source": [
        "# Handle Missing Values (Imputation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzFwisMBFYZT"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "cont_col = ['A2', 'A3', 'A8', 'A11', 'A14', 'A15']\n",
        "\n",
        "si_train_x = pd.DataFrame()\n",
        "si_test_x = pd.DataFrame()\n",
        "\n",
        "for col in train_x.columns:\n",
        "  if is_string_dtype(train_x[col].dtype):\n",
        "    si = SimpleImputer(strategy='most_frequent')\n",
        "  else:\n",
        "    si = SimpleImputer(strategy='mean')\n",
        "  si.fit(train_x[[col]])\n",
        "  si_train_x[col] = si.transform(train_x[[col]]).flatten()\n",
        "  si_test_x[col] = si.transform(test_x[[col]]).flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqeGVuZCIzIH"
      },
      "source": [
        "# Handle Continuous Feature (Binarization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbB2m-cwI6Tr",
        "outputId": "8163e57e-c429-4880-e09e-97e0f689d8a0"
      },
      "source": [
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "b_drop_train_x = pd.DataFrame()\n",
        "b_drop_test_x = pd.DataFrame()\n",
        "\n",
        "b_si_train_x = pd.DataFrame()\n",
        "b_si_test_x = pd.DataFrame()\n",
        "\n",
        "for col in train_x.columns:\n",
        "  if col in cont_col:\n",
        "    bin = Binarizer(threshold=drop_train_x[col].mean())\n",
        "    b_drop_train_x[col] = bin.transform(drop_train_x[[col]]).flatten()\n",
        "    b_drop_test_x[col] = bin.transform(drop_test_x[[col]]).flatten()\n",
        "\n",
        "    bin = Binarizer(threshold=si_train_x[col].mean())\n",
        "    b_si_train_x[col] = bin.transform(si_train_x[[col]]).flatten()\n",
        "    b_si_test_x[col] = bin.transform(si_test_x[[col]]).flatten()\n",
        "  else:\n",
        "    b_drop_train_x[col] = drop_train_x[col].copy()\n",
        "    b_drop_test_x[col] = drop_test_x[col].copy()\n",
        "    b_si_train_x[col] = si_train_x[col].copy()\n",
        "    b_si_test_x[col] = si_test_x[col].copy()\n",
        "\n",
        "print(b_drop_train_x.isnull().values.any())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_i4DOMgLIo8"
      },
      "source": [
        "# Handle Continuous Features (Quantization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3djsiBCiLk5Z"
      },
      "source": [
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "q_drop_train_x = pd.DataFrame()\n",
        "q_drop_test_x = pd.DataFrame()\n",
        "\n",
        "q_si_train_x = pd.DataFrame()\n",
        "q_si_test_x = pd.DataFrame()\n",
        "\n",
        "for col in train_x.columns:\n",
        "  if col in cont_col:\n",
        "    bin = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
        "    bin.fit(drop_train_x[[col]])\n",
        "    q_drop_train_x[col] = bin.transform(drop_train_x[[col]]).flatten()\n",
        "    q_drop_test_x[col] = bin.transform(drop_test_x[[col]]).flatten()\n",
        "    bin.fit(si_train_x[[col]])\n",
        "    q_si_train_x[col] = bin.transform(si_train_x[[col]]).flatten()\n",
        "    q_si_test_x[col] = bin.transform(si_test_x[[col]]).flatten()\n",
        "  else:\n",
        "    q_drop_train_x[col] = drop_train_x[col].copy()\n",
        "    q_drop_test_x[col] = drop_test_x[col].copy()\n",
        "    q_si_train_x[col] = si_train_x[col].copy()\n",
        "    q_si_test_x[col] = si_test_x[col].copy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUmMnrpzMbxb"
      },
      "source": [
        "# Handle Text Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsJbZjDAMeBx",
        "outputId": "0599f850-b992-480e-e005-c4255e4bc147"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "le.fit(train_y)\n",
        "train_y = le.transform(train_y)\n",
        "test_y = le.transform(test_y)\n",
        "\n",
        "le.fit(drop_train_y)\n",
        "drop_train_y = le.transform(drop_train_y)\n",
        "drop_test_y = le.transform(drop_test_y)\n",
        "\n",
        "cont_col = ['A2', 'A3', 'A8', 'A11', 'A14', 'A15']\n",
        "\n",
        "le_b_drop_train_x = pd.DataFrame()\n",
        "le_b_drop_test_x = pd.DataFrame()\n",
        "\n",
        "le_q_drop_train_x = pd.DataFrame()\n",
        "le_q_drop_test_x = pd.DataFrame()\n",
        "\n",
        "le_b_si_train_x = pd.DataFrame()\n",
        "le_b_si_test_x = pd.DataFrame()\n",
        "\n",
        "le_q_si_train_x = pd.DataFrame()\n",
        "le_q_si_test_x = pd.DataFrame()\n",
        "\n",
        "b_drop_train_x.reset_index(drop=True, inplace=True)\n",
        "q_drop_train_x.reset_index(drop=True, inplace=True)\n",
        "b_si_train_x.reset_index(drop=True, inplace=True)\n",
        "q_si_train_x.reset_index(drop=True, inplace=True)\n",
        "\n",
        "b_drop_test_x.reset_index(drop=True, inplace=True)\n",
        "q_drop_test_x.reset_index(drop=True, inplace=True)\n",
        "b_si_test_x.reset_index(drop=True, inplace=True)\n",
        "q_si_test_x.reset_index(drop=True, inplace=True)\n",
        "\n",
        "for col in train_x.columns:\n",
        "  if col not in cont_col:\n",
        "    le.fit(b_drop_train_x[[col]])\n",
        "    le_b_drop_train_x[col] = le.transform(b_drop_train_x[col])\n",
        "    le_b_drop_test_x[col] = le.transform(b_drop_test_x[col])\n",
        "\n",
        "    le.fit(q_drop_train_x[[col]])\n",
        "    le_q_drop_train_x[col] = le.transform(q_drop_train_x[[col]]).flatten()\n",
        "    le_q_drop_test_x[col] = le.transform(q_drop_test_x[[col]]).flatten()\n",
        "\n",
        "    le.fit(b_si_train_x[[col]])\n",
        "    le_b_si_train_x[col] = le.transform(b_si_train_x[[col]]).flatten()\n",
        "    le_b_si_test_x[col] = le.transform(b_si_test_x[[col]]).flatten()\n",
        "\n",
        "    le.fit(q_drop_train_x[[col]])\n",
        "    le_q_si_train_x[col] = le.transform(q_si_train_x[[col]]).flatten()\n",
        "    le_q_si_test_x[col] = le.transform(q_si_test_x[[col]]).flatten()\n",
        "\n",
        "  else:\n",
        "    le_b_drop_train_x[col] = b_drop_train_x[col].copy()\n",
        "    le_b_drop_test_x[col] = b_drop_test_x[col].copy()\n",
        "\n",
        "    le_q_drop_train_x[col] = q_drop_train_x[col].copy()\n",
        "    le_q_drop_test_x[col] = q_drop_test_x[col].copy()\n",
        "\n",
        "    le_b_si_train_x[col] = b_si_train_x[col].copy()\n",
        "    le_b_si_test_x[col] = b_si_test_x[col].copy()\n",
        "\n",
        "    le_q_si_train_x[col] = q_si_train_x[col].copy()\n",
        "    le_q_si_test_x[col] = q_si_test_x[col].copy()\n",
        "\n",
        "print(le_b_drop_train_x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     A1   A2   A3  A4  A5  A6  A7   A8  A9  A10  A11  A12  A13  A14  A15\n",
            "0     0  1.0  1.0   1   0   8   3  1.0   1    1    1    1    0  0.0    0\n",
            "1     0  0.0  1.0   2   2  13   3  0.0   0    0    0    1    0  0.0    0\n",
            "2     0  1.0  1.0   1   0  10   7  0.0   1    1    1    1    0  0.0    0\n",
            "3     1  1.0  0.0   1   0  10   7  1.0   1    0    0    0    2  0.0    0\n",
            "4     1  0.0  1.0   1   0   1   7  1.0   1    1    1    0    0  0.0    1\n",
            "..   ..  ...  ...  ..  ..  ..  ..  ...  ..  ...  ...  ...  ...  ...  ...\n",
            "582   1  1.0  1.0   1   0  12   7  0.0   1    1    1    0    0  0.0    0\n",
            "583   0  1.0  0.0   1   0   0   7  0.0   0    0    0    0    0  1.0    0\n",
            "584   1  1.0  0.0   1   0   2   3  1.0   1    1    1    0    0  1.0    0\n",
            "585   1  1.0  1.0   2   2   8   7  0.0   0    0    0    0    0  0.0    0\n",
            "586   1  0.0  1.0   1   0  10   7  0.0   1    1    0    0    0  0.0    0\n",
            "\n",
            "[587 rows x 15 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOE7aHiSPbKw"
      },
      "source": [
        "# Decision Tree (Train)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4OXIb4-Pfz5",
        "outputId": "492614d6-beb5-49eb-98bd-1eda81fda432"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt1 = DecisionTreeClassifier(criterion='entropy')\n",
        "dt2 = DecisionTreeClassifier(criterion='entropy')\n",
        "dt3 = DecisionTreeClassifier(criterion='entropy')\n",
        "dt4 = DecisionTreeClassifier(criterion='entropy')\n",
        "\n",
        "print(le_b_drop_train_x)\n",
        "\n",
        "dt1.fit(le_b_drop_train_x, drop_train_y)\n",
        "dt2.fit(le_q_drop_train_x, drop_train_y)\n",
        "dt3.fit(le_b_si_train_x, train_y)\n",
        "dt4.fit(le_q_si_train_x, train_y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     A1   A2   A3  A4  A5  A6  A7   A8  A9  A10  A11  A12  A13  A14  A15\n",
            "0     0  1.0  1.0   1   0   8   3  1.0   1    1    1    1    0  0.0    0\n",
            "1     0  0.0  1.0   2   2  13   3  0.0   0    0    0    1    0  0.0    0\n",
            "2     0  1.0  1.0   1   0  10   7  0.0   1    1    1    1    0  0.0    0\n",
            "3     1  1.0  0.0   1   0  10   7  1.0   1    0    0    0    2  0.0    0\n",
            "4     1  0.0  1.0   1   0   1   7  1.0   1    1    1    0    0  0.0    1\n",
            "..   ..  ...  ...  ..  ..  ..  ..  ...  ..  ...  ...  ...  ...  ...  ...\n",
            "582   1  1.0  1.0   1   0  12   7  0.0   1    1    1    0    0  0.0    0\n",
            "583   0  1.0  0.0   1   0   0   7  0.0   0    0    0    0    0  1.0    0\n",
            "584   1  1.0  0.0   1   0   2   3  1.0   1    1    1    0    0  1.0    0\n",
            "585   1  1.0  1.0   2   2   8   7  0.0   0    0    0    0    0  0.0    0\n",
            "586   1  0.0  1.0   1   0  10   7  0.0   1    1    0    0    0  0.0    0\n",
            "\n",
            "[587 rows x 15 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCyoKH8YQP2J"
      },
      "source": [
        "# Decision Tree (Test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txuDRIfpQPHR",
        "outputId": "c7bce981-b88c-4cda-cf30-60fcdf4cef47"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "b_drop_predict = dt1.predict(le_b_drop_test_x)\n",
        "q_drop_predict = dt2.predict(le_q_drop_test_x)\n",
        "b_si_predict = dt3.predict(le_b_si_test_x)\n",
        "q_si_predict = dt4.predict(le_q_si_test_x)\n",
        "\n",
        "acc1 = accuracy_score(drop_test_y, b_drop_predict)\n",
        "acc2 = accuracy_score(drop_test_y, q_drop_predict)\n",
        "acc3 = accuracy_score(test_y, b_si_predict)\n",
        "acc4 = accuracy_score(test_y, q_si_predict)\n",
        "\n",
        "print(acc1, acc2, acc3, acc4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8181818181818182 0.8333333333333334 0.8260869565217391 0.8260869565217391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lYmUDQXVaDJ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgDic_H5VZeQ",
        "outputId": "6a7eb05f-8dbc-4804-8c0e-2a19dfddb0c5"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(random_state=1, verbose=1)\n",
        "svm.fit(le_q_si_train_x, train_y)\n",
        "predict_y = svm.predict(le_q_si_test_x)\n",
        "\n",
        "acc = accuracy_score(test_y, q_si_predict)\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LibSVM]0.8260869565217391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cYy1Ia0WI8A"
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "et = ExtraTreesClassifier(n_estimators=1000, n_jobs=-1, random_state=1, verbose=1)\n",
        "et.fit(le_q_si_train_x, train_y)\n",
        "predict_y = et.predict(le_q_si_test_x)\n",
        "\n",
        "acc = accuracy_score(test_y, q_si_predict)\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}